{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3779d1e-54ed-4624-85c0-d15807c154cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/hari/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/hari/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/hari/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /Users/hari/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "from recipe_scrapers import scrape_me\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import nums_from_string\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.translate import bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d477b1b5-891b-4e2b-9f7b-f004ab64e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NY times had created a recipe parser previously, so we'll be using their training dataset here\n",
    "\n",
    "NYT_data = pd.read_csv(\"https://raw.githubusercontent.com/nytimes/ingredient-phrase-tagger/master/nyt-ingredients-snapshot-2015.csv\")\n",
    "NYT_data = NYT_data.dropna(axis = 0, subset = ['input', 'name'])\n",
    "NYT_data['input'] = NYT_data['input'].astype(str)\n",
    "NYT_data['name'] = NYT_data['name'].astype(str)\n",
    "NYT_data.reset_index(inplace = True)\n",
    "NYT_train_data = NYT_data[0:60000].copy()\n",
    "NYT_test_data = NYT_data[60001: 70000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2676bb50-8bee-4828-987a-32fdad7dbb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "vals = ['calories', 'carbohydrateContent', 'cholesterolContent', 'fatContent', \n",
    "        'fiberContent', 'proteinContent', 'saturatedFatContent', 'sodiumContent', 'sugarContent']\n",
    "replace_vals = {'½':'0.5', '¼':'0.25', '¾':'0.75', '⅓':'0.33', '⅛':'0.125'}\n",
    "sample_units = ['ounce', 'tablespoon', 'cup', 'pinch', 'dash', 'teaspoon', 'pound', 'clove', 'bunch',\n",
    "                   'slice', 'pint', 'quart', 'gallon', 'smidgen', 'drop', 'leaf', 'stalk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be50c29-74ee-48e9-a88c-3398c3a2d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using NLTK's preprocessing packages to retain nouns and remove units from the recipe inputs\n",
    "\n",
    "def preprocess(lines):  \n",
    "    tokenized = nltk.word_tokenize(lines.replace('-', ' '))\n",
    "    nouns = [wnl.lemmatize(word) for (word, pos) in nltk.pos_tag(tokenized) if (pos[0] == 'N') \n",
    "             and not (set(wnl.lemmatize(word).split())<=set(sample_units))] \n",
    "    return \" \".join(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b48c3de-7f4b-40b5-89b9-365de7edf315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>input</th>\n",
       "      <th>name</th>\n",
       "      <th>qty</th>\n",
       "      <th>range_end</th>\n",
       "      <th>unit</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>butternut squash package squash</td>\n",
       "      <td>butternut squash</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cup</td>\n",
       "      <td>cooked and pureed fresh, or 1 10-ounce package...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>chestnut chestnut</td>\n",
       "      <td>chestnuts</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cup</td>\n",
       "      <td>peeled and cooked fresh (about 20), or 1 cup c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>medium size onion</td>\n",
       "      <td>onion</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medium-size, peeled and chopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>celery coarse</td>\n",
       "      <td>celery</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stalk</td>\n",
       "      <td>chopped coarse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>oil</td>\n",
       "      <td>vegetable oil</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tablespoon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                            input              name   qty  \\\n",
       "0        0      0  butternut squash package squash  butternut squash  1.25   \n",
       "1        1      1                chestnut chestnut         chestnuts  1.00   \n",
       "2        2      2                medium size onion             onion  1.00   \n",
       "3        3      3                    celery coarse            celery  2.00   \n",
       "4        4      4                              oil     vegetable oil  1.50   \n",
       "\n",
       "   range_end        unit                                            comment  \n",
       "0        0.0         cup  cooked and pureed fresh, or 1 10-ounce package...  \n",
       "1        0.0         cup  peeled and cooked fresh (about 20), or 1 cup c...  \n",
       "2        0.0         NaN                    medium-size, peeled and chopped  \n",
       "3        0.0       stalk                                     chopped coarse  \n",
       "4        0.0  tablespoon                                                NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYT_train_data['input'] = NYT_train_data['input'].apply(preprocess).str.lower()\n",
    "NYT_test_data['input'] = NYT_test_data['input'].apply(preprocess).str.lower()\n",
    "\n",
    "NYT_train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d0fd651-73c8-4f22-af96-e62525642f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lime juice', {'entities': [(0, 10, 'INGREDIENT')]}),\n",
       " ('canola oil', {'entities': [(0, 10, 'INGREDIENT')]}),\n",
       " ('sprig cilantro', {'entities': [(6, 14, 'INGREDIENT')]}),\n",
       " ('pinch allspice', {'entities': [(6, 14, 'INGREDIENT')]}),\n",
       " ('shrimp shell', {'entities': [(0, 6, 'INGREDIENT')]})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It needs to be modified to be feed into spacy\n",
    "\n",
    "train_data = []\n",
    "D = {}\n",
    "remove_it = []\n",
    "for i in range(0,len(NYT_train_data)):\n",
    "    try:\n",
    "        train_input = NYT_train_data['input'].iloc[i].lower()\n",
    "        train_name = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", NYT_train_data['name'].iloc[i].lower())\n",
    "        ing_span = list(re.search(train_name, train_input).span(0))\n",
    "        ing_span.append('INGREDIENT')\n",
    "        train_data.append(tuple([train_input, {'entities':[tuple(ing_span)]}]))\n",
    "    except:\n",
    "        remove_it.append(i)\n",
    "\n",
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c685487d-3bc2-4419-8312-75df33479e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER training function\n",
    "\n",
    "def train_spacy(data,iterations):\n",
    "    TRAIN_DATA = data\n",
    "    nlp = spacy.blank('en')\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                nlp.update(\n",
    "                    [text],  # batch of texts\n",
    "                    [annotations],  # batch of annotations\n",
    "                    drop=0.2,  # dropout - make it harder to memorise data\n",
    "                    sgd=optimizer,  # callable to update weights\n",
    "                    losses=losses)\n",
    "            print(losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3631b6-e7e9-4b02-bf16-9bc3825b5f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:635: UserWarning: [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed. The languages with lexeme normalization tables are currently: da, de, el, en, id, lb, pt, ru, sr, ta, th.\n",
      "  proc.begin_training(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/thinc/neural/_classes/layernorm.py:74: RuntimeWarning: invalid value encountered in reciprocal\n",
      "  d_xhat = N * dy - sum_dy - dist * var ** (-1.0) * sum_dy_dist\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"fillet redfish saltwater fish\" with entities \"[(10, 14, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"herb bouquet parsley bay thyme cheesecloth\" with entities \"[(0, 13, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"ground round\" with entities \"[(1, 6, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"piece ginger\" with entities \"[(5, 12, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"bouquet garni parsley thyme\" with entities \"[(0, 14, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"lemon juice vinegar\" with entities \"[(0, 12, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"mackerel inch cube anchovy\" with entities \"[(0, 7, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"peel lemon peeler\" with entities \"[(5, 15, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"buttermilk\" with entities \"[(6, 10, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"peel orange peeler\" with entities \"[(5, 16, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"poussin chicken\" with entities \"[(0, 8, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"seville orange juice orange\" with entities \"[(0, 21, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"hog jowl strip bacon\" with entities \"[(0, 7, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"cut ziti zititagliata\" with entities \"[(0, 9, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"cornichons gherkin\" with entities \"[(0, 11, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"inch thick brioche cake\" with entities \"[(10, 18, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"nuoc mam fish sauce\" with entities \"[(0, 9, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"fish sauce pla market sauce\" with entities \"[(0, 11, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "/Users/hari/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"lemongrass\" with entities \"[(0, 9, 'INGREDIENT')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 10150.83349870116}\n",
      "Starting iteration 1\n",
      "{'ner': 7843.8731352400155}\n",
      "Starting iteration 2\n",
      "{'ner': 6992.24295245788}\n",
      "Starting iteration 3\n",
      "{'ner': 6834.62282536902}\n",
      "Starting iteration 4\n",
      "{'ner': 6763.189041783452}\n",
      "Starting iteration 5\n",
      "{'ner': 6733.351075279356}\n",
      "Starting iteration 6\n",
      "{'ner': 6728.688280357612}\n",
      "Starting iteration 7\n",
      "{'ner': 6675.776740410404}\n",
      "Starting iteration 8\n",
      "{'ner': 6784.386944055014}\n",
      "Starting iteration 9\n",
      "{'ner': 6676.828302753115}\n",
      "Starting iteration 10\n",
      "{'ner': 6936.306281837478}\n",
      "Starting iteration 11\n",
      "{'ner': 6855.2506828468495}\n",
      "Starting iteration 12\n",
      "{'ner': 6893.504319110884}\n",
      "Starting iteration 13\n",
      "{'ner': 6805.664210935306}\n",
      "Starting iteration 14\n",
      "{'ner': 6839.5646593293895}\n",
      "Starting iteration 15\n",
      "{'ner': 6950.107948716004}\n",
      "Starting iteration 16\n",
      "{'ner': 7069.2384099950605}\n",
      "Starting iteration 17\n",
      "{'ner': 7242.32866150697}\n",
      "Starting iteration 18\n",
      "{'ner': 7216.364709123974}\n",
      "Starting iteration 19\n",
      "{'ner': 7271.90398641402}\n",
      "Starting iteration 20\n",
      "{'ner': 7332.1790249097}\n",
      "Starting iteration 21\n",
      "{'ner': 7315.274993159146}\n",
      "Starting iteration 22\n",
      "{'ner': 7213.871388662444}\n",
      "Starting iteration 23\n",
      "{'ner': 7278.167442820789}\n",
      "Starting iteration 24\n",
      "{'ner': 7502.893204744669}\n"
     ]
    }
   ],
   "source": [
    "ner_model = train_spacy(train_data, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d1c492-7f9f-42f7-a427-7161c4f73f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save function to disk. This can be called later\n",
    "\n",
    "ner_model.to_disk(\"ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e85cdb-9871-4975-8618-4b5b07902736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salt',\n",
       " 'coriander',\n",
       " 'chilies',\n",
       " 'salt',\n",
       " 'pepper',\n",
       " 'parmigiano reggiano',\n",
       " 'avocado',\n",
       " 'onion',\n",
       " 'tomato',\n",
       " 'potato',\n",
       " 'tomato',\n",
       " 'garlic',\n",
       " 'oil',\n",
       " 'pepper',\n",
       " 'arugula',\n",
       " 'egg',\n",
       " 'olive',\n",
       " 'egg',\n",
       " 'thyme',\n",
       " 'dijon mustard']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = []\n",
    "for i in NYT_test_data.input:\n",
    "    if len(ner_model(preprocess(i)).ents) > 0:\n",
    "        test_output.append(ner_model(preprocess(i)).ents[0].text)\n",
    "    else:\n",
    "        test_output.append('')\n",
    "\n",
    "test_output[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7978a872-3056-439e-b461-fdfc4a4ff08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing for accuracy based on sub string match. \n",
    "#If the algorithm identifies a word out of the n-grm string, its considered a match\n",
    "\n",
    "results = {'1':0, '0':0}\n",
    "for i in range(0,len(test_output)):\n",
    "    if re.search(re.escape(test_output[i]),NYT_test_data.name.iloc[i].lower()):\n",
    "        results['1'] += 1\n",
    "    else:\n",
    "        results['0'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acbb7652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm correctly idenitfies (atleast part of) 92.78% of the ingredients\n"
     ]
    }
   ],
   "source": [
    "accuracy = results['1']/len(test_output)*100\n",
    "print(\"The algorithm correctly idenitfies (atleast part of) {}% of the ingredients\".format(round(accuracy, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0535418-7c48-438d-b3f0-1cc282eab251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_clean(serving_size):\n",
    "    return (int(serving_size.split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78931122-0069-4f68-a50a-2194b0011b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calorie_clean(nutrients_info):\n",
    "    \n",
    "    ret_vals = []\n",
    "    \n",
    "    for i in vals:\n",
    "        ret_vals.append(float(nutrients_info[i].split(' ')[0]))\n",
    "    \n",
    "    return ret_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7c58c93-fea3-4b12-997c-8c5f5b057fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(ing):\n",
    "    \n",
    "    ing = re.sub(r'½|¼|¾|⅓|⅛','', ing)\n",
    "    b = ner_model(preprocess(ing))\n",
    "    \n",
    "    return b.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2577e1a-ea9b-4b34-93ff-ffdaf1252a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vulgar_convert(ing_frac_value):\n",
    "    \n",
    "    for i in replace_vals.keys():\n",
    "        if i in ing_frac_value:\n",
    "            ing_frac_value = ing_frac_value.replace(i, replace_vals[i])\n",
    "    \n",
    "    return ing_frac_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67fe633a-3927-4b62-8534-1dd6d3545b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quant(ing):\n",
    "    \n",
    "    x = nums_from_string.get_nums(vulgar_convert(ing))\n",
    "    \n",
    "    if len(x)==1:\n",
    "        quant = x[0]\n",
    "    elif re.search(r'-?\\(\\d+\\.?\\d*\\)*', ing):\n",
    "        if len(x) == 2:\n",
    "            quant = x[0]*x[1]\n",
    "        else:\n",
    "            quant = (x[0]+x[1])*x[2]\n",
    "    elif len(x)==0:\n",
    "        quant=1\n",
    "    else:\n",
    "        quant = x[0]+x[1]\n",
    "        \n",
    "    return quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eedbfc6c-6056-438f-954c-1155ee8cf0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit(ing):\n",
    "    \n",
    "    words = [wnl.lemmatize(i) for i in ing.replace('(','').replace(')','').split(' ')]\n",
    "    unit = 'count'\n",
    "    \n",
    "    for word in words:\n",
    "        if word in sample_units:\n",
    "            unit = word\n",
    "            break\n",
    "    \n",
    "    return unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a0d8a3f-da6d-4a29-b523-bf68df583502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is obtained from the Kaggle dataset - grabbing only the recipesIDs\n",
    "#The rest of the informatin is obatined as we scrap it using the IDs from allrecipes.com\n",
    "\n",
    "with open('Recipes.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "a = []\n",
    "\n",
    "for i in range(1,len(lines)):\n",
    "    a.append(lines[i].split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c374eee-7681-467a-9e34-13a98a8bc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing a list of list using hearder names\n",
    "\n",
    "recipes_df = [['RecipeID', 'Title', 'Serving_size', 'Prep_time', 'Calories', 'Carbs', 'Cholestrol', \n",
    "         'Fats', 'Fiber', 'Protein', 'SaturatedFat', 'Sodium', 'Sugar', 'Image']]\n",
    "ing_df = [['RecipeID', 'IngredientName', 'Quantity', 'Unit']]\n",
    "skippers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08b17549-3a3d-4721-9e53-0262ad6ebc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_items(j):\n",
    "    try:\n",
    "        scraper = scrape_me('https://www.allrecipes.com/recipe/' + j + '/')\n",
    "        recipes_df.append([j, \n",
    "                     scraper.title(), \n",
    "                     serving_clean(scraper.yields()), \n",
    "                     int(scraper.total_time()), \n",
    "                     calorie_clean(scraper.nutrients())[0], \n",
    "                     calorie_clean(scraper.nutrients())[1],\n",
    "                     calorie_clean(scraper.nutrients())[2],\n",
    "                     calorie_clean(scraper.nutrients())[3],\n",
    "                     calorie_clean(scraper.nutrients())[4],\n",
    "                     calorie_clean(scraper.nutrients())[5],\n",
    "                     calorie_clean(scraper.nutrients())[6],\n",
    "                     calorie_clean(scraper.nutrients())[7],\n",
    "                     calorie_clean(scraper.nutrients())[8],\n",
    "                     scraper.image()])\n",
    "        for i in scraper.ingredients():\n",
    "            if len(get_name(i))>0:\n",
    "                ing_df.append([j, get_name(i)[0].text.lower(), get_quant(i), get_unit(i)]) \n",
    "    except:\n",
    "        skippers.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cab5650b-b896-412d-b108-4dab7d2322ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running processes concurrently\n",
    "with ThreadPoolExecutor(max_workers = None) as executor:\n",
    "    futures = [executor.submit(process_items, x) for x in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8690810d-7540-4ad4-8a34-7dff5f5aa3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40156, 14)\n"
     ]
    }
   ],
   "source": [
    "#Convert recipes list to dataframe and remove duplicates added due to multiprocessing\n",
    "df_recipes = pd.DataFrame(recipes_df[1:])\n",
    "df_recipes.columns = recipes_df[0]\n",
    "df_recipes = df_recipes.drop_duplicates()\n",
    "print(df_recipes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "105b126a-a63b-484b-b346-63d6ee569fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356385, 4)\n"
     ]
    }
   ],
   "source": [
    "#Convert ingredients - recipe relation to dataframe and drop duplicates\n",
    "df_rec2ing = pd.DataFrame(ing_df[1:])\n",
    "df_rec2ing.columns = ing_df[0]\n",
    "df_rec2ing = df_rec2ing.drop_duplicates()\n",
    "print(df_rec2ing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f79d00d6-cb47-4ea4-9ba2-ff86291260f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4046, 2)\n"
     ]
    }
   ],
   "source": [
    "#Create a ingredients table, add a column for ingredientID and drop duplicates\n",
    "df_ingredient = df_rec2ing['IngredientName'].to_frame()\n",
    "df_ingredient = df_ingredient.drop_duplicates()\n",
    "df_ingredient['IngredientID'] = df_ingredient.index\n",
    "df_ingredient = df_ingredient[['IngredientID', 'IngredientName']]\n",
    "print(df_ingredient.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "872980b7-d9ad-4ed6-ba66-3f6759c5cba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeID</th>\n",
       "      <th>IngredientID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258163</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>260453</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245714</td>\n",
       "      <td>2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258163</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222388</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>pound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RecipeID  IngredientID  Quantity   Unit\n",
       "0   258163             0      2.00  count\n",
       "1   260453             1      0.75    cup\n",
       "2   245714             2      4.00  count\n",
       "3   258163             3      1.00  count\n",
       "4   222388             4      3.00  pound"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace ingredient names on recipe-ingredient relation to ingredientIDs\n",
    "df_rec2ing['IngredientName'] = df_rec2ing['IngredientName'].map(df_ingredient.set_index('IngredientName')['IngredientID'])\n",
    "df_rec2ing.rename(columns={\"IngredientName\": \"IngredientID\"}, inplace=True)\n",
    "df_rec2ing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7876914-4731-4d23-9321-3e909e77b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding rating to the recipes table. This is obtained from the Kaggle dataset\n",
    "df_full = pd.read_csv(\"raw-data_recipe.csv\")\n",
    "\n",
    "df_full = df_full[['recipe_id', 'aver_rate', 'review_nums']]\n",
    "df_full.columns = ['RecipeID', 'Average_rating', 'No_of_reviews']\n",
    "df_full = df_full.astype(str)\n",
    "df_recipes = df_recipes.merge(df_full, on = 'RecipeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "275e86f1-8bf5-4f81-8018-e7e580733cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to file uploaded by colleague where recipes where tagged as vegan or not\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "dbfile = './git_repo/recipe_recommender/datasets/recipes.db'\n",
    "cnx = sqlite3.connect(dbfile)\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM is_vegan;\", cnx)\n",
    "df = df.astype(str)\n",
    "df.drop('index',axis=1, inplace=True)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.rename(columns = {'recipe_id':'RecipeID' }, inplace=True)\n",
    "\n",
    "df_recipes = df_recipes.merge(df, on = 'RecipeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8fc2de85-ae83-4ce8-93f6-882c90246f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-60-dafdf9068908>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_recipes['Prep_time'][df_recipes['Prep_time'] == 0] = 10\n"
     ]
    }
   ],
   "source": [
    "#Recipes that supposedly take not time still requires atleast a few mins to prep\n",
    "df_recipes['Prep_time'][df_recipes['Prep_time'] == 0] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "093da9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Serving_size</th>\n",
       "      <th>Prep_time</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Carbs</th>\n",
       "      <th>Cholestrol</th>\n",
       "      <th>Fats</th>\n",
       "      <th>Fiber</th>\n",
       "      <th>Protein</th>\n",
       "      <th>SaturatedFat</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Image</th>\n",
       "      <th>Average_rating</th>\n",
       "      <th>No_of_reviews</th>\n",
       "      <th>isVegan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258163</td>\n",
       "      <td>Schnitzel Sandwich</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>913.5</td>\n",
       "      <td>112.3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>https://imagesvc.meredithcorp.io/v3/mm/image?u...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222388</td>\n",
       "      <td>Homemade Bacon</td>\n",
       "      <td>8</td>\n",
       "      <td>710</td>\n",
       "      <td>308.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>61.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2017.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>https://imagesvc.meredithcorp.io/v3/mm/image?u...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245714</td>\n",
       "      <td>Potato Bacon Pizza</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>162.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>21.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>189.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>https://imagesvc.meredithcorp.io/v3/mm/image?u...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260453</td>\n",
       "      <td>Fresh Balsamic Chicken Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>453.7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>188.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>https://imagesvc.meredithcorp.io/v3/mm/image?u...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103305</td>\n",
       "      <td>Hearty Chili</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>447.6</td>\n",
       "      <td>37.4</td>\n",
       "      <td>69.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>28.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>https://imagesvc.meredithcorp.io/v3/mm/image?u...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RecipeID                         Title  Serving_size  Prep_time  Calories  \\\n",
       "0   258163            Schnitzel Sandwich             4         40     913.5   \n",
       "1   222388                Homemade Bacon             8        710     308.1   \n",
       "2   245714            Potato Bacon Pizza             2         70     162.7   \n",
       "3   260453  Fresh Balsamic Chicken Salad             2         26     453.7   \n",
       "4   103305                  Hearty Chili             8         70     447.6   \n",
       "\n",
       "   Carbs  Cholestrol  Fats  Fiber  Protein  SaturatedFat  Sodium  Sugar  \\\n",
       "0  112.3       119.0  35.3    6.0     34.1           6.7  1164.0    7.1   \n",
       "1    1.8        61.7  23.6    0.5     21.0           7.7  2017.1    0.1   \n",
       "2   16.5        21.6   7.6    0.7      7.1           4.0   189.8    2.5   \n",
       "3   31.0        82.5  22.6    3.0     33.6           4.3   188.1   17.9   \n",
       "4   37.4        69.6  19.0   11.8     28.5           7.1  1445.0   10.6   \n",
       "\n",
       "                                               Image Average_rating  \\\n",
       "0  https://imagesvc.meredithcorp.io/v3/mm/image?u...            5.0   \n",
       "1  https://imagesvc.meredithcorp.io/v3/mm/image?u...            5.0   \n",
       "2  https://imagesvc.meredithcorp.io/v3/mm/image?u...            4.5   \n",
       "3  https://imagesvc.meredithcorp.io/v3/mm/image?u...            4.0   \n",
       "4  https://imagesvc.meredithcorp.io/v3/mm/image?u...           4.25   \n",
       "\n",
       "  No_of_reviews isVegan  \n",
       "0             1       0  \n",
       "1             3       0  \n",
       "2             2       0  \n",
       "3             1       0  \n",
       "4             3       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeID</th>\n",
       "      <th>IngredientID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258163</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>260453</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245714</td>\n",
       "      <td>2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258163</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222388</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>pound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RecipeID  IngredientID  Quantity   Unit\n",
       "0   258163             0      2.00  count\n",
       "1   260453             1      0.75    cup\n",
       "2   245714             2      4.00  count\n",
       "3   258163             3      1.00  count\n",
       "4   222388             4      3.00  pound"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IngredientID</th>\n",
       "      <th>IngredientName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>chicken breast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vinegar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pork</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IngredientID  IngredientName\n",
       "0             0  chicken breast\n",
       "1             1         vinegar\n",
       "2             2          potato\n",
       "3             3            salt\n",
       "4             4            pork"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_recipes.head())\n",
    "display(df_rec2ing.head())\n",
    "display(df_ingredient.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30e3b08d-cd81-4a5a-9995-d70a3f0ff666",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './git_repo/recipe_recommender/datasets/'\n",
    "df_recipes.to_csv(file_name + 'Recipes.csv', encoding='utf-8', index = None)\n",
    "df_rec2ing.to_csv(file_name + 'Rec2Ing.csv', encoding='utf-8', index = None)\n",
    "df_ingredient.to_csv(file_name + 'Ingredients.csv', encoding='utf-8', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
